[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "深層学習ノート",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nCategories\n\n\n\n\n\n\n2024-11-20\n\n\ntweetデータを用いた自然言語分類モデルをつくってみる①\n\n\nkaggle, nlp, fastai\n\n\n\n\n2024-11-20\n\n\nMNIST画像分類モデルを実装してみよう\n\n\nkaggle, mnist, fastai\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/mnist_kaggle/index.html",
    "href": "posts/mnist_kaggle/index.html",
    "title": "MNIST画像分類モデルを実装してみよう",
    "section": "",
    "text": "このノートでは、kaggleのMNIST(手書き数字データ)を用いた画像分類を行なっていきます。深層学習にはfastaiライブラリーを使用します。MNIST手書き数字データは、機械学習界隈のHello Worldのような、誰もが最初に通るデータセットです。ここでは複雑なモデルは用いず、三層のモデルとresnet18モデルの二つを使用します。目標は99% accuracyで数字を分類できるモデルをつくることです。対象読者はkaggleの画像コンペの始め方が分からないけど興味がある人です。MNIST画像は一見簡単そうに見えますが、初学者には取っ付きにくいものです。特に、学習に時間がかかる問題にどのように対処するのか、モデルの成果をどう測るのかといった詰まりポイントを重点的に見ていきます。逆にモデル設計の詳細(畳み込み層の動きなど)は見ていきません。\n–\n実装の流れは以下の通りです。\n\n必要なライブラリのインストール\nデータセットのインストール\nトレーニングデータとテストデータの差異を確認\nサンプルデータ上でのトレーニング\nトレーニング結果の妥当性を確認\nデータセット全体でのトレーニング\nまとめ\n参照ページ\n\n\n以下のコードは実行環境にCUDA(GPU)が使用可能かを確認します。このノートはGPUが使えることを前提に動いています。kaggleの上でも無料でGPUが使えますが、クラウドのサービス(paperspace, google colabなど)の方がモデルの学習を早くできるのでお勧めです。\n\n!nvidia-smi\n\nThu Oct 31 02:47:40 2024       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n| 41%   37C    P8    16W / 140W |      1MiB / 16376MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n\n\n\nfastkaggleはfastaiとkaggle apiを合わせたライプラリーです。ここで用いられている全インポートimport *は、fastai推奨のインポート方法です。私自身、初めは慣れずに居心地が悪い表記方法でしたが今は慣れました。jupyter notebookなどの実験(仮説と検証を繰り返す)環境では全インポートで問題ありません。\n\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    !pip install -Uq fastkaggle\n\nfrom fastkaggle import *\nfrom fastai.vision.all import *\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n\n\n\n\n\n\n\nまずkaggleのコンペ参加には同意が必要になります。同意が済んだら、次はapiキーの取得です。/root/.config/kaggle/kaggle.jsonファイルに取得したapiキーを記述します。ファイルは以下のコードで作成します。\n\n!mkdir /root/.config/kaggle\n!touch /root/.config/kaggle/kaggle.json\n\n\n\n\nsetup_comp関数でデータセットをdigit-recognizerフォルダーにインストールします。ここでエラーが出た場合は、もう一度apiキーが設定されているか、競技の同意が済んでいるかを見てみます。よくあるエラー原因は競技名のスペルミスです。\n\ncomp = \"digit-recognizer\"\n\npath = setup_comp(comp)\npath.ls()\n\nWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.config/kaggle/kaggle.json'\nDownloading digit-recognizer.zip to /notebooks\n\n\n100%|██████████| 15.3M/15.3M [00:00&lt;00:00, 74.5MB/s]\n\n\n\n\n\n(#3) [Path('digit-recognizer/sample_submission.csv'),Path('digit-recognizer/test.csv'),Path('digit-recognizer/train.csv')]\n\n\nトレーニングデータは42000、テストデータは28000サンプルあることがわかります。\n\ntrn_df = pd.read_csv(path/\"train.csv\")\ntst_df = pd.read_csv(path/\"test.csv\")\nsmp_df = pd.read_csv(path/\"sample_submission.csv\")\n\ntrn_df.shape, tst_df.shape, smp_df.shape\n\n((42000, 785), (28000, 784), (28000, 2))\n\n\n\n\n\n最初の行(label行)にはデータのラベルが、その他の行(pixel0 - 783行)にはピクセルデータが格納されていることがわかります。このデータは色(color channel)の無い白黒画像であることが推測できます。\n\ntrn_df.head(n=3)\n\n\n\n\n\n\n\n\nlabel\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n3 rows × 785 columns\n\n\n\nラベルは0から9の10ラベルです。それぞれ約4000個と、おおよそ均等に配分されたデータセットであることが分かります。\n\ntrn_df[\"label\"].unique()\n\narray([1, 0, 4, 7, 3, 5, 8, 9, 2, 6])\n\n\n\ntrn_df.groupby(\"label\").size().plot.barh();\n\n\n\n\n\n\n\n\nラベルとピクセルデータ(画像)が対応していることを確認します。\n\nidx = 0\nlabel, img_val = trn_df.iloc[idx, 0], trn_df.iloc[idx, 1:].values\n\nshow_image(img_val.reshape((28, 28)), title=label);\n\n\n\n\n\n\n\n\n\n\n\ntrainとtestフォルダそれぞれに画像データを保存します。\n\n!mkdir {path}/train\n!mkdir {path}/test\npath.ls()\n\n(#5) [Path('digit-recognizer/train'),Path('digit-recognizer/sample_submission.csv'),Path('digit-recognizer/test.csv'),Path('digit-recognizer/train.csv'),Path('digit-recognizer/test')]\n\n\n\ndef save_img(img, f_path):\n    img = img.reshape((28, 28))\n    img = Image.fromarray(img.astype(\"uint8\"))\n    img.save(f_path)\n\n\nfor idx, row in trn_df.iterrows():\n    label, img = row[0], row[1:]\n\n    f_path = f\"{path}/train/{label}_{idx}.jpg\"\n    save_img(img.values, f_path)\n\n\n(path/\"train\").ls()\n\n(#42000) [Path('digit-recognizer/train/7_19624.jpg'),Path('digit-recognizer/train/2_40612.jpg'),Path('digit-recognizer/train/3_32852.jpg'),Path('digit-recognizer/train/1_13520.jpg'),Path('digit-recognizer/train/9_29764.jpg'),Path('digit-recognizer/train/6_16260.jpg'),Path('digit-recognizer/train/9_18518.jpg'),Path('digit-recognizer/train/0_13218.jpg'),Path('digit-recognizer/train/5_32574.jpg'),Path('digit-recognizer/train/7_20089.jpg')...]\n\n\n\nfor idx, img in tst_df.iterrows():\n    f_path = f\"{path}/test/{idx}.jpg\"\n    save_img(img.values, f_path)\n\n\n(path/\"test\").ls()\n\n(#28000) [Path('digit-recognizer/test/13420.jpg'),Path('digit-recognizer/test/22873.jpg'),Path('digit-recognizer/test/6022.jpg'),Path('digit-recognizer/test/13644.jpg'),Path('digit-recognizer/test/1332.jpg'),Path('digit-recognizer/test/3737.jpg'),Path('digit-recognizer/test/617.jpg'),Path('digit-recognizer/test/10239.jpg'),Path('digit-recognizer/test/14546.jpg'),Path('digit-recognizer/test/4200.jpg')...]\n\n\n\n\n\n\nまず分類モデルを作る前に、二つのデータセット(トレーニング・テスト)に違いがないこと確認します。例えばトレーニングセットには0から9までの数字画像が、テストセットには10から19までの数字といった全く違う種類のデータが入っているかもしれません。二つのデータセットに差異がないことは、この後の分類モデルを作る際の前提になります。 二つのデータセットの差異確認は深層学習モデルを用いて行います。ここでのラベルはtrain/testとなり、モデルは画像がどちらのデータセットに属しているのかを予測します。全データセット70000に対して、トレーニングは42000、テストは28000あります。もし、モデルが0.6 accuracy(42000/70000=0.6)から離れた値を出す場合、二つのデータセットは異なる種類のものであると推測できます。\n\ndef label_func(f_path): return f_path.parent.name\n\nlabel_func((path/\"train\").ls()[0]), label_func((path/\"test\").ls()[0])\n\n('train', 'test')\n\n\n\ndef get_db(size=28):\n    return DataBlock(\n        blocks=(ImageBlock, CategoryBlock),\n        get_items=get_image_files,\n        get_y=label_func,\n        splitter=RandomSplitter(),\n        item_tfms=Resize(size),\n        batch_tfms=[*aug_transforms(do_flip=False, min_scale=0.8), Normalize.from_stats(*imagenet_stats)]\n    )\n\nmnist = get_db()\n\n学習用のデータセットを用意する場合、全トレーニングデータを使う必要はありません。アイデアの有効性を試す実験段階では、開発サイクルを高速で回すためにも少ないサンプル数を使用します。 ここではランダムに、トレーニングデータセットから10%のデータを取得しています。どのようにサンプルデータを用意するのかは様々な手法がありますが、今回のような画像分類モデルでは、各ラベルのサンプル数が300ほどあれば実験用途として十分な気がします。以下のdls.show_batchによる画像の表示は、ざっとデータを理解するのに役立ちます。トレーニングの前段階で、トレーニングデータ(画像+対応するラベル)を確認するのは必須ステップです。\n\ndef get_dls(db, path, sample=1, bs=256):\n    # https://knowing.net/posts/2022/05/fastai-dataloaders/\n    dls = db.dataloaders(path, bs=bs)\n    selected_items = random.sample(dls.train_ds.items,  int(len(dls.train_ds.items)*sample))\n    dls.train = dls.test_dl(selected_items, with_labels=True)\n    return dls\n\ndls = get_dls(mnist, path, sample=0.1)\ndls.show_batch(max_n=20, nrows=2, ncols=10)\n\n\n\n\n\n\n\n\nモデルの設計は入力/出力を中心に行います。fastaiはPytorchの上に作られたライブラリーなので、画像型は(N, C, H, W)、つまり(バッチ数, カラーチャンネル, 縦, 横)としてモデルに入力されます。モデルの出力はデータセットのラベル数dls.cによって決まります。ここではモデルは画像がトレーニング・テストセットのどちらに属しているのかを予測します。\n\ndef get_model():\n    return nn.Sequential(\n        nn.Conv2d(3, 1, 1),\n        # nn.Upsample(size=(28, 28)), # Needs Upsample layer if you'll use learn.tta() later\n        nn.Flatten(1),\n        nn.Dropout(0.1),\n        nn.Linear(28*28, 100),\n        nn.BatchNorm1d(100),\n        nn.Dropout(0.2),\n        nn.ReLU(),\n        nn.Linear(100, dls.c)\n    )\n\nget_model()\n\nSequential(\n  (0): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Dropout(p=0.1, inplace=False)\n  (3): Linear(in_features=784, out_features=100, bias=True)\n  (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (5): Dropout(p=0.2, inplace=False)\n  (6): ReLU()\n  (7): Linear(in_features=100, out_features=2, bias=True)\n)\n\n\n学習に必要なデータセットの用意・モデルの設計が済んだら、いよいよトレーニングの開始です。learn.lr_find関数で学習率を求めたらトレーニングサイクルを回します。\n\nlearn = Learner(dls, get_model(), loss_func=CrossEntropyLossFlat(), metrics=accuracy).to_fp16()\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.015848932787775993)\n\n\n\n\n\n\n\n\n\n結果はおおよそ59% accuracyで、画像がどちらのデータセットに属しているのかを予測しています。二つのデータセットに差異はなさそうです。\n\nlearn.fit_one_cycle(4, lr_max=slice(3e-3, 3e-2))\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.710549\n0.795406\n0.597000\n00:13\n\n\n1\n0.700336\n0.704644\n0.568500\n00:12\n\n\n2\n0.688758\n0.678533\n0.596929\n00:12\n\n\n3\n0.674994\n0.681112\n0.586357\n00:11\n\n\n\n\n\n\n\n\nでは、本題の画像分類モデルのトレーニングに移っていきます。サンプルデータの用意・画像の表示を行い、モデルの学習率を求めます。先のデータと同じ画像データを用いますが、今回は対応するラベルが異なります。ここでは、モデルは画像が0から9までのどの数字であるかを予測します。\n\ndef label_func(f_path): return f_path.name.split(\"_\")[0]\n\n(path/\"train\").ls()[0], label_func((path/\"train\").ls()[0])\n\n(Path('digit-recognizer/train/7_19624.jpg'), '7')\n\n\n\nmnist = get_db()\ndls = get_dls(mnist, path/\"train\", sample=0.1)\ndls.show_batch(max_n=30, nrows=3, ncols=10)\n\n\n\n\n\n\n\n\n\nlearn = Learner(dls, get_model(), loss_func=CrossEntropyLossFlat(), metrics=accuracy).to_fp16()\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0014454397605732083)\n\n\n\n\n\n\n\n\n\nおおよそ0.91 accuracyの精度のモデルを、10%のトレーニングデータで作りました。この時点でトレーニングデータを増やし、モデルの精度を高めようとする方法がありますが、これは間違いです。トレーニングデータ量を増やすことは過学習を防ぐのに有効ですが、学習不足には違う対処が求められます。 まずは他のモデルの精度と比較して、学習済みのモデルが過学習か学習不足かを見ていきます。ここではresnet18を比較モデルとします。\n\nlearn.fit_one_cycle(6, lr_max=slice(3e-3, 1e-2))\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.595407\n1.169721\n0.635357\n00:07\n\n\n1\n1.004385\n0.500168\n0.851667\n00:03\n\n\n2\n0.707560\n0.360822\n0.888214\n00:03\n\n\n3\n0.542243\n0.318499\n0.904405\n00:03\n\n\n4\n0.434244\n0.306300\n0.910000\n00:03\n\n\n5\n0.363178\n0.299947\n0.909881\n00:03\n\n\n\n\n\n\nlearn = Learner(dls, resnet18(), loss_func=CrossEntropyLossFlat(), metrics=accuracy).to_fp16()\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n先のモデルと比較して、resnet18はより精度の高いモデルであることが分かります。モデル精度の比較結果から、先のモデルは学習不足であったことが分かります。一般的に、過学習になる前段階で注意するポイントは学習不足です。学習不足にはより複雑なモデルが有効です。トレーニングサイクルを増やす、学習率を少し上げるなども学習不足に効果的です。よくある間違いは、過学習になる前(学習不足段階)に過学習を防ぐ手法(データ量を増やす、データ拡張、regularizationなど)を用いることです。過学習への対処は、過学習が起きた後に行います。起きる前、予防的には行いません。\n\nlearn.fine_tune(6, 3e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.481695\n1.180103\n0.615119\n00:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.227101\n0.339515\n0.909167\n00:03\n\n\n1\n0.168335\n0.627921\n0.838571\n00:04\n\n\n2\n0.143743\n0.432962\n0.900833\n00:03\n\n\n3\n0.120995\n0.268689\n0.937381\n00:03\n\n\n4\n0.091097\n0.148554\n0.959881\n00:03\n\n\n5\n0.066370\n0.122915\n0.967143\n00:03\n\n\n\n\n\nトレーニング・検証データそれぞれの損失を見てきます。トレーニングデータの損失はスムーズな減少が見られますが、検証データの損失はスムーズではない形で推移しています。一つ考えられる原因は、重みの更新が急であることです。スムーズな損失の推移には、いくつかの正則化テクニックが効果的です。weight decayを後のトレーニングで試していきたいと思います。\n\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n\n\n\n\n学習済みのモデルが数字を正しく予測しているか、検証画像(学習していないデータ)を用いて見ていきます。おおよそ、モデルは正しく手書き画像を分類できていることが分かります。\n\nlearn.show_results(max_n=20, nrows=2, ncols=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n逆に、モデルがどの数字画像を正しく予測できていないかを見ていきます。2と7、4と9の数字ペアの分類が、モデルの最も不得意とする画像であることが分かります。\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.most_confused(min_val=15)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[('2', '7', 20), ('4', '9', 19)]\n\n\nここではモデルが実際に間違えた予測をしている画像を見ていきます。ざっくりと見た時、モデルが間違えた画像は人間が見ても間違えそうな、紛らわしい数字であることが見て取れます。この紛らわしいラベルへの対処方としては、label smoothingの導入があります。\n\ninterp.plot_top_losses(k=20, nrows=2, ncols=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nでは先のトレーニング結果を踏まえて、再度トレーニングをしていきます。モデル・データセットは同様に、label smoothing・weight decayを新たに使用します。label smoothing関数はラベルのノイズを抑え損失を滑らかにしますが、より多くのトレーニングサイクルを必要とします。先のトレーニングとの相違点は、accuracyの精度は上がっている一方、lossが以前より高い値であることです。ここでの注意点は、accuracyの精度を見ること・lossは参考程度に見ることです。lossはモデルがトレーニングしやすいように設計された関数の出力です。見るべき大事なポイント(モデルの精度)はaccuracyです。\n\nlearn = Learner(dls, resnet18(), loss_func=LabelSmoothingCrossEntropyFlat(), metrics=accuracy).to_fp16()\nlearn.fine_tune(9, 2e-3, wd=0.03)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.378253\n2.647140\n0.526190\n00:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.336900\n1.490081\n0.937024\n00:03\n\n\n1\n1.207181\n1.428404\n0.939048\n00:03\n\n\n2\n1.151014\n1.397945\n0.923333\n00:03\n\n\n3\n1.131866\n1.395567\n0.904762\n00:03\n\n\n4\n1.111709\n1.244161\n0.941310\n00:03\n\n\n5\n1.094381\n1.210672\n0.945476\n00:03\n\n\n6\n1.079392\n1.151900\n0.958809\n00:03\n\n\n7\n1.064843\n1.112762\n0.970357\n00:03\n\n\n8\n1.053271\n1.109932\n0.971310\n00:03\n\n\n\n\n\nモデルの精度・loss推移の滑らかさともに向上しています。\n\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n\n\n\n今度は全トレーニングデータを用いて学習サイクルを回します。ここでのポイントは、ぼーっと学習の進行を見ない・ノートブックから離れることです。\n\ndls = get_dls(mnist, path/\"train\", sample=1) # Use all training image samples\nlearn = Learner(dls, resnet18(), loss_func=LabelSmoothingCrossEntropyFlat(), metrics=accuracy).to_fp16()\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0006918309954926372)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(15, 1e-3, wd=0.03)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.352898\n1.110789\n0.974286\n00:32\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.050016\n1.066425\n0.983810\n00:33\n\n\n1\n1.039457\n1.074759\n0.982262\n00:33\n\n\n2\n1.050062\n1.090605\n0.977381\n00:33\n\n\n3\n1.048530\n1.073222\n0.982857\n00:35\n\n\n4\n1.041486\n1.075171\n0.981310\n00:34\n\n\n5\n1.038663\n1.071839\n0.983929\n00:35\n\n\n6\n1.031112\n1.061485\n0.986905\n00:36\n\n\n7\n1.026435\n1.066055\n0.985714\n00:34\n\n\n8\n1.025973\n1.065412\n0.985833\n00:34\n\n\n9\n1.020517\n1.052722\n0.990000\n00:35\n\n\n10\n1.018529\n1.049975\n0.989643\n00:35\n\n\n11\n1.016169\n1.046174\n0.991429\n00:34\n\n\n12\n1.015739\n1.046068\n0.991071\n00:34\n\n\n13\n1.015518\n1.045375\n0.991548\n00:40\n\n\n14\n1.015467\n1.045369\n0.991548\n00:42\n\n\n\n\n\n\n\n\nでは、学習済みモデルの精度をテストデータで評価していきます。まずはテストファイルを名前順にソートし、テスト画像(ラベルは含まれていない)を表示します。learn.dls.test_dlは、トレーニング画像と同じ下処理を、テスト画像に行う便利な関数です。\n\n# https://stackoverflow.com/questions/33159106/sort-filenames-in-directory-in-ascending-order\nordered_tst_files = get_image_files(path/\"test\").sorted(key=lambda f:  int(re.findall(\"(\\d+).jpg$\", f.name)[0]))\nordered_tst_files[:10]\n\n(#10) [Path('digit-recognizer/test/0.jpg'),Path('digit-recognizer/test/1.jpg'),Path('digit-recognizer/test/2.jpg'),Path('digit-recognizer/test/3.jpg'),Path('digit-recognizer/test/4.jpg'),Path('digit-recognizer/test/5.jpg'),Path('digit-recognizer/test/6.jpg'),Path('digit-recognizer/test/7.jpg'),Path('digit-recognizer/test/8.jpg'),Path('digit-recognizer/test/9.jpg')]\n\n\n\ntest_dl = learn.dls.test_dl(ordered_tst_files)\ntest_dl.show_batch(max_n=10, nrows=1, ncols=10)\n\n\n\n\n\n\n\n\n学習済みモデルにテスト画像を予測(分類)させます。\n\npreds = learn.get_preds(dl=test_dl, with_decoded=True)\npreds\n\n\n\n\n\n\n\n\n(tensor([[7.9680e-05, 5.4073e-05, 8.9991e-01,  ..., 9.6678e-05, 9.9019e-05,\n          1.0097e-04],\n         [8.9885e-01, 7.8046e-05, 1.3502e-04,  ..., 1.0204e-04, 1.0433e-04,\n          9.8660e-05],\n         [7.4821e-05, 1.0368e-04, 1.0127e-04,  ..., 1.0342e-04, 1.0242e-04,\n          1.0302e-04],\n         ...,\n         [6.9998e-05, 5.2941e-05, 2.7252e-05,  ..., 1.0606e-04, 1.0679e-04,\n          9.8137e-05],\n         [9.9981e-05, 8.6992e-05, 9.6574e-05,  ..., 1.0136e-04, 1.0376e-04,\n          9.7474e-05],\n         [5.9522e-05, 4.7224e-05, 9.0107e-01,  ..., 8.9877e-05, 9.8856e-05,\n          9.8278e-05]]),\n None,\n tensor([2, 0, 9,  ..., 3, 9, 2]))\n\n\n予測した数字が妥当かどうか、画像と一緒に見比べてみます。モデルはテスト画像の数字を分類できていそうです。\n\nprint(preds[2][:10])\ntest_dl.show_batch(max_n=10, nrows=1, ncols=10)\n\ntensor([2, 0, 9, 0, 3, 7, 0, 3, 0, 3])\n\n\n\n\n\n\n\n\n\n予測した値をcsvファイルに保存し、kaggleに提出します。\n\nsmp_df[\"Label\"] = preds[2].apply_(lambda x: int(learn.dls.vocab[x]))\nsmp_df.to_csv(path/\"submission.csv\", index=False)\n!head {path}/submission.csv\n\nImageId,Label\n1,2\n2,0\n3,9\n4,0\n5,3\n6,7\n7,0\n8,3\n9,0\n\n\n\nfrom kaggle import api\napi.competition_submit_cli(path/\"submission.csv\", \"first model\", comp)\n\n100%|██████████| 208k/208k [00:00&lt;00:00, 657kB/s]\n\n\nSuccessfully submitted to Digit Recognizer\n\n\n最後にインストールしたzipファイルと画像ファイルを削除します。\n\n!rm -rf {path}\n!rm -rf digit-recognizer.zip\n\n\n\n\n\n\n\n\nkaggle の結果\n\n\n目標値99% accuracyを達成することができました。今回のポイント三点をまとめていきます。\n\n少ないサンプル数を使用して、高速な開発サイクルを回す。 → 全サンプルを使用するのは、一番最後に。\n過学習の対処は過学習が起きた後に行う。 → 予防的には行わない。先に注意するのは学習不足とその対処。\nモデル精度の評価はメトリックを見る。 → 損失の推移は参考程度に。\n\nもしも読者がこのノートを役に立ったと思ったら、リアクションボタンを押してもらえると幸いです。質問や間違いがあれば、以下コメント欄に書き込んでください。\n\n\n\n\nkaggle公式競技ページ\nmnistデータセットのwiki\nfastaiのクリエイター(Jeremy Howardさん)のノートブック\n他の競技参加者(Jacopo Repossiさん)のノートブック"
  },
  {
    "objectID": "posts/mnist_kaggle/index.html#hello-world-in-deep-learning",
    "href": "posts/mnist_kaggle/index.html#hello-world-in-deep-learning",
    "title": "MNIST画像分類モデルを実装してみよう",
    "section": "",
    "text": "このノートでは、kaggleのMNIST(手書き数字データ)を用いた画像分類を行なっていきます。深層学習にはfastaiライブラリーを使用します。MNIST手書き数字データは、機械学習界隈のHello Worldのような、誰もが最初に通るデータセットです。ここでは複雑なモデルは用いず、三層のモデルとresnet18モデルの二つを使用します。目標は99% accuracyで数字を分類できるモデルをつくることです。対象読者はkaggleの画像コンペの始め方が分からないけど興味がある人です。MNIST画像は一見簡単そうに見えますが、初学者には取っ付きにくいものです。特に、学習に時間がかかる問題にどのように対処するのか、モデルの成果をどう測るのかといった詰まりポイントを重点的に見ていきます。逆にモデル設計の詳細(畳み込み層の動きなど)は見ていきません。\n–\n実装の流れは以下の通りです。\n\n必要なライブラリのインストール\nデータセットのインストール\nトレーニングデータとテストデータの差異を確認\nサンプルデータ上でのトレーニング\nトレーニング結果の妥当性を確認\nデータセット全体でのトレーニング\nまとめ\n参照ページ\n\n\n以下のコードは実行環境にCUDA(GPU)が使用可能かを確認します。このノートはGPUが使えることを前提に動いています。kaggleの上でも無料でGPUが使えますが、クラウドのサービス(paperspace, google colabなど)の方がモデルの学習を早くできるのでお勧めです。\n\n!nvidia-smi\n\nThu Oct 31 02:47:40 2024       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n| 41%   37C    P8    16W / 140W |      1MiB / 16376MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n\n\n\nfastkaggleはfastaiとkaggle apiを合わせたライプラリーです。ここで用いられている全インポートimport *は、fastai推奨のインポート方法です。私自身、初めは慣れずに居心地が悪い表記方法でしたが今は慣れました。jupyter notebookなどの実験(仮説と検証を繰り返す)環境では全インポートで問題ありません。\n\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    !pip install -Uq fastkaggle\n\nfrom fastkaggle import *\nfrom fastai.vision.all import *\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n\n\n\n\n\n\n\nまずkaggleのコンペ参加には同意が必要になります。同意が済んだら、次はapiキーの取得です。/root/.config/kaggle/kaggle.jsonファイルに取得したapiキーを記述します。ファイルは以下のコードで作成します。\n\n!mkdir /root/.config/kaggle\n!touch /root/.config/kaggle/kaggle.json\n\n\n\n\nsetup_comp関数でデータセットをdigit-recognizerフォルダーにインストールします。ここでエラーが出た場合は、もう一度apiキーが設定されているか、競技の同意が済んでいるかを見てみます。よくあるエラー原因は競技名のスペルミスです。\n\ncomp = \"digit-recognizer\"\n\npath = setup_comp(comp)\npath.ls()\n\nWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.config/kaggle/kaggle.json'\nDownloading digit-recognizer.zip to /notebooks\n\n\n100%|██████████| 15.3M/15.3M [00:00&lt;00:00, 74.5MB/s]\n\n\n\n\n\n(#3) [Path('digit-recognizer/sample_submission.csv'),Path('digit-recognizer/test.csv'),Path('digit-recognizer/train.csv')]\n\n\nトレーニングデータは42000、テストデータは28000サンプルあることがわかります。\n\ntrn_df = pd.read_csv(path/\"train.csv\")\ntst_df = pd.read_csv(path/\"test.csv\")\nsmp_df = pd.read_csv(path/\"sample_submission.csv\")\n\ntrn_df.shape, tst_df.shape, smp_df.shape\n\n((42000, 785), (28000, 784), (28000, 2))\n\n\n\n\n\n最初の行(label行)にはデータのラベルが、その他の行(pixel0 - 783行)にはピクセルデータが格納されていることがわかります。このデータは色(color channel)の無い白黒画像であることが推測できます。\n\ntrn_df.head(n=3)\n\n\n\n\n\n\n\n\nlabel\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n3 rows × 785 columns\n\n\n\nラベルは0から9の10ラベルです。それぞれ約4000個と、おおよそ均等に配分されたデータセットであることが分かります。\n\ntrn_df[\"label\"].unique()\n\narray([1, 0, 4, 7, 3, 5, 8, 9, 2, 6])\n\n\n\ntrn_df.groupby(\"label\").size().plot.barh();\n\n\n\n\n\n\n\n\nラベルとピクセルデータ(画像)が対応していることを確認します。\n\nidx = 0\nlabel, img_val = trn_df.iloc[idx, 0], trn_df.iloc[idx, 1:].values\n\nshow_image(img_val.reshape((28, 28)), title=label);\n\n\n\n\n\n\n\n\n\n\n\ntrainとtestフォルダそれぞれに画像データを保存します。\n\n!mkdir {path}/train\n!mkdir {path}/test\npath.ls()\n\n(#5) [Path('digit-recognizer/train'),Path('digit-recognizer/sample_submission.csv'),Path('digit-recognizer/test.csv'),Path('digit-recognizer/train.csv'),Path('digit-recognizer/test')]\n\n\n\ndef save_img(img, f_path):\n    img = img.reshape((28, 28))\n    img = Image.fromarray(img.astype(\"uint8\"))\n    img.save(f_path)\n\n\nfor idx, row in trn_df.iterrows():\n    label, img = row[0], row[1:]\n\n    f_path = f\"{path}/train/{label}_{idx}.jpg\"\n    save_img(img.values, f_path)\n\n\n(path/\"train\").ls()\n\n(#42000) [Path('digit-recognizer/train/7_19624.jpg'),Path('digit-recognizer/train/2_40612.jpg'),Path('digit-recognizer/train/3_32852.jpg'),Path('digit-recognizer/train/1_13520.jpg'),Path('digit-recognizer/train/9_29764.jpg'),Path('digit-recognizer/train/6_16260.jpg'),Path('digit-recognizer/train/9_18518.jpg'),Path('digit-recognizer/train/0_13218.jpg'),Path('digit-recognizer/train/5_32574.jpg'),Path('digit-recognizer/train/7_20089.jpg')...]\n\n\n\nfor idx, img in tst_df.iterrows():\n    f_path = f\"{path}/test/{idx}.jpg\"\n    save_img(img.values, f_path)\n\n\n(path/\"test\").ls()\n\n(#28000) [Path('digit-recognizer/test/13420.jpg'),Path('digit-recognizer/test/22873.jpg'),Path('digit-recognizer/test/6022.jpg'),Path('digit-recognizer/test/13644.jpg'),Path('digit-recognizer/test/1332.jpg'),Path('digit-recognizer/test/3737.jpg'),Path('digit-recognizer/test/617.jpg'),Path('digit-recognizer/test/10239.jpg'),Path('digit-recognizer/test/14546.jpg'),Path('digit-recognizer/test/4200.jpg')...]\n\n\n\n\n\n\nまず分類モデルを作る前に、二つのデータセット(トレーニング・テスト)に違いがないこと確認します。例えばトレーニングセットには0から9までの数字画像が、テストセットには10から19までの数字といった全く違う種類のデータが入っているかもしれません。二つのデータセットに差異がないことは、この後の分類モデルを作る際の前提になります。 二つのデータセットの差異確認は深層学習モデルを用いて行います。ここでのラベルはtrain/testとなり、モデルは画像がどちらのデータセットに属しているのかを予測します。全データセット70000に対して、トレーニングは42000、テストは28000あります。もし、モデルが0.6 accuracy(42000/70000=0.6)から離れた値を出す場合、二つのデータセットは異なる種類のものであると推測できます。\n\ndef label_func(f_path): return f_path.parent.name\n\nlabel_func((path/\"train\").ls()[0]), label_func((path/\"test\").ls()[0])\n\n('train', 'test')\n\n\n\ndef get_db(size=28):\n    return DataBlock(\n        blocks=(ImageBlock, CategoryBlock),\n        get_items=get_image_files,\n        get_y=label_func,\n        splitter=RandomSplitter(),\n        item_tfms=Resize(size),\n        batch_tfms=[*aug_transforms(do_flip=False, min_scale=0.8), Normalize.from_stats(*imagenet_stats)]\n    )\n\nmnist = get_db()\n\n学習用のデータセットを用意する場合、全トレーニングデータを使う必要はありません。アイデアの有効性を試す実験段階では、開発サイクルを高速で回すためにも少ないサンプル数を使用します。 ここではランダムに、トレーニングデータセットから10%のデータを取得しています。どのようにサンプルデータを用意するのかは様々な手法がありますが、今回のような画像分類モデルでは、各ラベルのサンプル数が300ほどあれば実験用途として十分な気がします。以下のdls.show_batchによる画像の表示は、ざっとデータを理解するのに役立ちます。トレーニングの前段階で、トレーニングデータ(画像+対応するラベル)を確認するのは必須ステップです。\n\ndef get_dls(db, path, sample=1, bs=256):\n    # https://knowing.net/posts/2022/05/fastai-dataloaders/\n    dls = db.dataloaders(path, bs=bs)\n    selected_items = random.sample(dls.train_ds.items,  int(len(dls.train_ds.items)*sample))\n    dls.train = dls.test_dl(selected_items, with_labels=True)\n    return dls\n\ndls = get_dls(mnist, path, sample=0.1)\ndls.show_batch(max_n=20, nrows=2, ncols=10)\n\n\n\n\n\n\n\n\nモデルの設計は入力/出力を中心に行います。fastaiはPytorchの上に作られたライブラリーなので、画像型は(N, C, H, W)、つまり(バッチ数, カラーチャンネル, 縦, 横)としてモデルに入力されます。モデルの出力はデータセットのラベル数dls.cによって決まります。ここではモデルは画像がトレーニング・テストセットのどちらに属しているのかを予測します。\n\ndef get_model():\n    return nn.Sequential(\n        nn.Conv2d(3, 1, 1),\n        # nn.Upsample(size=(28, 28)), # Needs Upsample layer if you'll use learn.tta() later\n        nn.Flatten(1),\n        nn.Dropout(0.1),\n        nn.Linear(28*28, 100),\n        nn.BatchNorm1d(100),\n        nn.Dropout(0.2),\n        nn.ReLU(),\n        nn.Linear(100, dls.c)\n    )\n\nget_model()\n\nSequential(\n  (0): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Dropout(p=0.1, inplace=False)\n  (3): Linear(in_features=784, out_features=100, bias=True)\n  (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (5): Dropout(p=0.2, inplace=False)\n  (6): ReLU()\n  (7): Linear(in_features=100, out_features=2, bias=True)\n)\n\n\n学習に必要なデータセットの用意・モデルの設計が済んだら、いよいよトレーニングの開始です。learn.lr_find関数で学習率を求めたらトレーニングサイクルを回します。\n\nlearn = Learner(dls, get_model(), loss_func=CrossEntropyLossFlat(), metrics=accuracy).to_fp16()\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.015848932787775993)\n\n\n\n\n\n\n\n\n\n結果はおおよそ59% accuracyで、画像がどちらのデータセットに属しているのかを予測しています。二つのデータセットに差異はなさそうです。\n\nlearn.fit_one_cycle(4, lr_max=slice(3e-3, 3e-2))\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.710549\n0.795406\n0.597000\n00:13\n\n\n1\n0.700336\n0.704644\n0.568500\n00:12\n\n\n2\n0.688758\n0.678533\n0.596929\n00:12\n\n\n3\n0.674994\n0.681112\n0.586357\n00:11\n\n\n\n\n\n\n\n\nでは、本題の画像分類モデルのトレーニングに移っていきます。サンプルデータの用意・画像の表示を行い、モデルの学習率を求めます。先のデータと同じ画像データを用いますが、今回は対応するラベルが異なります。ここでは、モデルは画像が0から9までのどの数字であるかを予測します。\n\ndef label_func(f_path): return f_path.name.split(\"_\")[0]\n\n(path/\"train\").ls()[0], label_func((path/\"train\").ls()[0])\n\n(Path('digit-recognizer/train/7_19624.jpg'), '7')\n\n\n\nmnist = get_db()\ndls = get_dls(mnist, path/\"train\", sample=0.1)\ndls.show_batch(max_n=30, nrows=3, ncols=10)\n\n\n\n\n\n\n\n\n\nlearn = Learner(dls, get_model(), loss_func=CrossEntropyLossFlat(), metrics=accuracy).to_fp16()\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0014454397605732083)\n\n\n\n\n\n\n\n\n\nおおよそ0.91 accuracyの精度のモデルを、10%のトレーニングデータで作りました。この時点でトレーニングデータを増やし、モデルの精度を高めようとする方法がありますが、これは間違いです。トレーニングデータ量を増やすことは過学習を防ぐのに有効ですが、学習不足には違う対処が求められます。 まずは他のモデルの精度と比較して、学習済みのモデルが過学習か学習不足かを見ていきます。ここではresnet18を比較モデルとします。\n\nlearn.fit_one_cycle(6, lr_max=slice(3e-3, 1e-2))\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.595407\n1.169721\n0.635357\n00:07\n\n\n1\n1.004385\n0.500168\n0.851667\n00:03\n\n\n2\n0.707560\n0.360822\n0.888214\n00:03\n\n\n3\n0.542243\n0.318499\n0.904405\n00:03\n\n\n4\n0.434244\n0.306300\n0.910000\n00:03\n\n\n5\n0.363178\n0.299947\n0.909881\n00:03\n\n\n\n\n\n\nlearn = Learner(dls, resnet18(), loss_func=CrossEntropyLossFlat(), metrics=accuracy).to_fp16()\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n先のモデルと比較して、resnet18はより精度の高いモデルであることが分かります。モデル精度の比較結果から、先のモデルは学習不足であったことが分かります。一般的に、過学習になる前段階で注意するポイントは学習不足です。学習不足にはより複雑なモデルが有効です。トレーニングサイクルを増やす、学習率を少し上げるなども学習不足に効果的です。よくある間違いは、過学習になる前(学習不足段階)に過学習を防ぐ手法(データ量を増やす、データ拡張、regularizationなど)を用いることです。過学習への対処は、過学習が起きた後に行います。起きる前、予防的には行いません。\n\nlearn.fine_tune(6, 3e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.481695\n1.180103\n0.615119\n00:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.227101\n0.339515\n0.909167\n00:03\n\n\n1\n0.168335\n0.627921\n0.838571\n00:04\n\n\n2\n0.143743\n0.432962\n0.900833\n00:03\n\n\n3\n0.120995\n0.268689\n0.937381\n00:03\n\n\n4\n0.091097\n0.148554\n0.959881\n00:03\n\n\n5\n0.066370\n0.122915\n0.967143\n00:03\n\n\n\n\n\nトレーニング・検証データそれぞれの損失を見てきます。トレーニングデータの損失はスムーズな減少が見られますが、検証データの損失はスムーズではない形で推移しています。一つ考えられる原因は、重みの更新が急であることです。スムーズな損失の推移には、いくつかの正則化テクニックが効果的です。weight decayを後のトレーニングで試していきたいと思います。\n\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n\n\n\n\n学習済みのモデルが数字を正しく予測しているか、検証画像(学習していないデータ)を用いて見ていきます。おおよそ、モデルは正しく手書き画像を分類できていることが分かります。\n\nlearn.show_results(max_n=20, nrows=2, ncols=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n逆に、モデルがどの数字画像を正しく予測できていないかを見ていきます。2と7、4と9の数字ペアの分類が、モデルの最も不得意とする画像であることが分かります。\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.most_confused(min_val=15)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[('2', '7', 20), ('4', '9', 19)]\n\n\nここではモデルが実際に間違えた予測をしている画像を見ていきます。ざっくりと見た時、モデルが間違えた画像は人間が見ても間違えそうな、紛らわしい数字であることが見て取れます。この紛らわしいラベルへの対処方としては、label smoothingの導入があります。\n\ninterp.plot_top_losses(k=20, nrows=2, ncols=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nでは先のトレーニング結果を踏まえて、再度トレーニングをしていきます。モデル・データセットは同様に、label smoothing・weight decayを新たに使用します。label smoothing関数はラベルのノイズを抑え損失を滑らかにしますが、より多くのトレーニングサイクルを必要とします。先のトレーニングとの相違点は、accuracyの精度は上がっている一方、lossが以前より高い値であることです。ここでの注意点は、accuracyの精度を見ること・lossは参考程度に見ることです。lossはモデルがトレーニングしやすいように設計された関数の出力です。見るべき大事なポイント(モデルの精度)はaccuracyです。\n\nlearn = Learner(dls, resnet18(), loss_func=LabelSmoothingCrossEntropyFlat(), metrics=accuracy).to_fp16()\nlearn.fine_tune(9, 2e-3, wd=0.03)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n3.378253\n2.647140\n0.526190\n00:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.336900\n1.490081\n0.937024\n00:03\n\n\n1\n1.207181\n1.428404\n0.939048\n00:03\n\n\n2\n1.151014\n1.397945\n0.923333\n00:03\n\n\n3\n1.131866\n1.395567\n0.904762\n00:03\n\n\n4\n1.111709\n1.244161\n0.941310\n00:03\n\n\n5\n1.094381\n1.210672\n0.945476\n00:03\n\n\n6\n1.079392\n1.151900\n0.958809\n00:03\n\n\n7\n1.064843\n1.112762\n0.970357\n00:03\n\n\n8\n1.053271\n1.109932\n0.971310\n00:03\n\n\n\n\n\nモデルの精度・loss推移の滑らかさともに向上しています。\n\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n\n\n\n今度は全トレーニングデータを用いて学習サイクルを回します。ここでのポイントは、ぼーっと学習の進行を見ない・ノートブックから離れることです。\n\ndls = get_dls(mnist, path/\"train\", sample=1) # Use all training image samples\nlearn = Learner(dls, resnet18(), loss_func=LabelSmoothingCrossEntropyFlat(), metrics=accuracy).to_fp16()\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0006918309954926372)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(15, 1e-3, wd=0.03)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.352898\n1.110789\n0.974286\n00:32\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.050016\n1.066425\n0.983810\n00:33\n\n\n1\n1.039457\n1.074759\n0.982262\n00:33\n\n\n2\n1.050062\n1.090605\n0.977381\n00:33\n\n\n3\n1.048530\n1.073222\n0.982857\n00:35\n\n\n4\n1.041486\n1.075171\n0.981310\n00:34\n\n\n5\n1.038663\n1.071839\n0.983929\n00:35\n\n\n6\n1.031112\n1.061485\n0.986905\n00:36\n\n\n7\n1.026435\n1.066055\n0.985714\n00:34\n\n\n8\n1.025973\n1.065412\n0.985833\n00:34\n\n\n9\n1.020517\n1.052722\n0.990000\n00:35\n\n\n10\n1.018529\n1.049975\n0.989643\n00:35\n\n\n11\n1.016169\n1.046174\n0.991429\n00:34\n\n\n12\n1.015739\n1.046068\n0.991071\n00:34\n\n\n13\n1.015518\n1.045375\n0.991548\n00:40\n\n\n14\n1.015467\n1.045369\n0.991548\n00:42\n\n\n\n\n\n\n\n\nでは、学習済みモデルの精度をテストデータで評価していきます。まずはテストファイルを名前順にソートし、テスト画像(ラベルは含まれていない)を表示します。learn.dls.test_dlは、トレーニング画像と同じ下処理を、テスト画像に行う便利な関数です。\n\n# https://stackoverflow.com/questions/33159106/sort-filenames-in-directory-in-ascending-order\nordered_tst_files = get_image_files(path/\"test\").sorted(key=lambda f:  int(re.findall(\"(\\d+).jpg$\", f.name)[0]))\nordered_tst_files[:10]\n\n(#10) [Path('digit-recognizer/test/0.jpg'),Path('digit-recognizer/test/1.jpg'),Path('digit-recognizer/test/2.jpg'),Path('digit-recognizer/test/3.jpg'),Path('digit-recognizer/test/4.jpg'),Path('digit-recognizer/test/5.jpg'),Path('digit-recognizer/test/6.jpg'),Path('digit-recognizer/test/7.jpg'),Path('digit-recognizer/test/8.jpg'),Path('digit-recognizer/test/9.jpg')]\n\n\n\ntest_dl = learn.dls.test_dl(ordered_tst_files)\ntest_dl.show_batch(max_n=10, nrows=1, ncols=10)\n\n\n\n\n\n\n\n\n学習済みモデルにテスト画像を予測(分類)させます。\n\npreds = learn.get_preds(dl=test_dl, with_decoded=True)\npreds\n\n\n\n\n\n\n\n\n(tensor([[7.9680e-05, 5.4073e-05, 8.9991e-01,  ..., 9.6678e-05, 9.9019e-05,\n          1.0097e-04],\n         [8.9885e-01, 7.8046e-05, 1.3502e-04,  ..., 1.0204e-04, 1.0433e-04,\n          9.8660e-05],\n         [7.4821e-05, 1.0368e-04, 1.0127e-04,  ..., 1.0342e-04, 1.0242e-04,\n          1.0302e-04],\n         ...,\n         [6.9998e-05, 5.2941e-05, 2.7252e-05,  ..., 1.0606e-04, 1.0679e-04,\n          9.8137e-05],\n         [9.9981e-05, 8.6992e-05, 9.6574e-05,  ..., 1.0136e-04, 1.0376e-04,\n          9.7474e-05],\n         [5.9522e-05, 4.7224e-05, 9.0107e-01,  ..., 8.9877e-05, 9.8856e-05,\n          9.8278e-05]]),\n None,\n tensor([2, 0, 9,  ..., 3, 9, 2]))\n\n\n予測した数字が妥当かどうか、画像と一緒に見比べてみます。モデルはテスト画像の数字を分類できていそうです。\n\nprint(preds[2][:10])\ntest_dl.show_batch(max_n=10, nrows=1, ncols=10)\n\ntensor([2, 0, 9, 0, 3, 7, 0, 3, 0, 3])\n\n\n\n\n\n\n\n\n\n予測した値をcsvファイルに保存し、kaggleに提出します。\n\nsmp_df[\"Label\"] = preds[2].apply_(lambda x: int(learn.dls.vocab[x]))\nsmp_df.to_csv(path/\"submission.csv\", index=False)\n!head {path}/submission.csv\n\nImageId,Label\n1,2\n2,0\n3,9\n4,0\n5,3\n6,7\n7,0\n8,3\n9,0\n\n\n\nfrom kaggle import api\napi.competition_submit_cli(path/\"submission.csv\", \"first model\", comp)\n\n100%|██████████| 208k/208k [00:00&lt;00:00, 657kB/s]\n\n\nSuccessfully submitted to Digit Recognizer\n\n\n最後にインストールしたzipファイルと画像ファイルを削除します。\n\n!rm -rf {path}\n!rm -rf digit-recognizer.zip\n\n\n\n\n\n\n\n\nkaggle の結果\n\n\n目標値99% accuracyを達成することができました。今回のポイント三点をまとめていきます。\n\n少ないサンプル数を使用して、高速な開発サイクルを回す。 → 全サンプルを使用するのは、一番最後に。\n過学習の対処は過学習が起きた後に行う。 → 予防的には行わない。先に注意するのは学習不足とその対処。\nモデル精度の評価はメトリックを見る。 → 損失の推移は参考程度に。\n\nもしも読者がこのノートを役に立ったと思ったら、リアクションボタンを押してもらえると幸いです。質問や間違いがあれば、以下コメント欄に書き込んでください。\n\n\n\n\nkaggle公式競技ページ\nmnistデータセットのwiki\nfastaiのクリエイター(Jeremy Howardさん)のノートブック\n他の競技参加者(Jacopo Repossiさん)のノートブック"
  },
  {
    "objectID": "posts/tweet_kaggle/index.html",
    "href": "posts/tweet_kaggle/index.html",
    "title": "tweetデータを用いた自然言語分類モデルをつくってみる①",
    "section": "",
    "text": "このノートでは、kaggleのNLP(自然言語処理)を行う方法を紹介します。tweetデータから、そのtweetが災害についての発信であるかを分類します。深層学習にはfastaiライブラリーを使用します。目標は80% f1 scoreでtweetを分類するモデルをつくることです。80%はAutoMLのスコアを基にしたものです。\n–\n実装の流れは以下の通りです。\n\n必要なライブラリのインストール\n分類モデル用データセットを用意\n分類モデルの作成\nkaggleに提出\nまとめ\n参照リンク\n\n\n\n競技参加の同意・APIキーの取得を、テータセットのインストール前に行っていきましょう。\n\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    %pip install -Uq fastkaggle\n\nfrom fastkaggle import *\nfrom fastai.text.all import *\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n!mkdir /root/.config/kaggle\n!touch /root/.config/kaggle/kaggle.json\n\n\n\n\ntweetデータはcsvファイルで取得されます。各データセットのサンプル数は、トレーニングが7613、テストが3263です。一つの列に対して、1tweet・対応するラベル(1が災害、0が災害以外のtweet)が含まれています。\n\ncomp = \"nlp-getting-started\"\n\npath = setup_comp(comp)\npath.ls()\n\nWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.config/kaggle/kaggle.json'\n\n\n(#3) [Path('nlp-getting-started/sample_submission.csv'),Path('nlp-getting-started/test.csv'),Path('nlp-getting-started/train.csv')]\n\n\n\ntrn_df = pd.read_csv(path/\"train.csv\")\ntst_df = pd.read_csv(path/\"test.csv\")\nsmp_df = pd.read_csv(path/\"sample_submission.csv\")\n\ntrn_df.shape, tst_df.shape, smp_df.shape\n\n((7613, 5), (3263, 4), (3263, 2))\n\n\n\ntrn_df.head()\n\n\n\n\n\n\n\n\nid\nkeyword\nlocation\ntext\ntarget\n\n\n\n\n0\n1\nNaN\nNaN\nOur Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n1\n\n\n1\n4\nNaN\nNaN\nForest fire near La Ronge Sask. Canada\n1\n\n\n2\n5\nNaN\nNaN\nAll residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n1\n\n\n3\n6\nNaN\nNaN\n13,000 people receive #wildfires evacuation orders in California\n1\n\n\n4\n7\nNaN\nNaN\nJust got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school\n1\n\n\n\n\n\n\n\nトレーニングデータにはいくつかの重複データが含まれていますが、特にtextデータの重複には注意が必要です。学習・検証データを作成する際に、同一データが二つのデータセットにまたがって含まれないようにします。例えば、11-Year-Old Boy Charged...の文章が検証データに含まれている場合、学習データはそのtweetデータを含まないことになります。広く使用されているランダムな学習セットの用意は、このデータには不適切であることが分かります。\n\ntrn_df.describe(include=\"object\")\n\n\n\n\n\n\n\n\nkeyword\nlocation\ntext\n\n\n\n\ncount\n7552\n5080\n7613\n\n\nunique\n221\n3341\n7503\n\n\ntop\nfatalities\nUSA\n11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...\n\n\nfreq\n45\n104\n10\n\n\n\n\n\n\n\nここでは、以下の学習データセットに対してtargetの割合がどう変化するかを示します。面白い点は、keywordデータの欠如が災害tweetの割合を増やしている点です。一方locationデータの有無は、災害tweetの割合に影響を与えていません。これが何を示すのかは分かりませんが、keywordを含ませると何らかの情報(災害に関する)をモデルに渡すことが推測できます。\n\ndef plot_target(df, title=\"\"):\n    plt.figure(figsize=(8, 6))\n    plt.pie(df[\"target\"].value_counts(), labels=df[\"target\"].unique(), autopct='%1.1f%%')\n    plt.title(title)\n    plt.show()\n\nplot_target(trn_df, \"Distribution of Target Values\")\n\n\n\n\n\n\n\n\n\nplot_target(trn_df[pd.isna(trn_df.keyword)], \"Distribution of Target Values on nan keyword\")\n\n\n\n\n\n\n\n\n\nplot_target(trn_df[pd.isna(trn_df.location)], \"Distribution of Target Values on nan location\")\n\n\n\n\n\n\n\n\n以下の関数random_splitterは、学習・検証セット間の同一データの重複(data leakage)を防ぎます。\n\ndef random_splitter(df, val_pct=0.2):\n    df = df.copy()\n    df[\"uniq_text\"] = df[\"text\"].map(lambda x: hash(x))\n    uniq_text = df[\"uniq_text\"].unique()\n    val_text_ids = set(random.sample(list(uniq_text), int(len(uniq_text) * val_pct)))\n\n    trn_idx = df.index[~df[\"uniq_text\"].isin(val_text_ids)].tolist()\n    val_idx = df.index[df[\"uniq_text\"].isin(val_text_ids)].tolist()\n    return trn_idx, val_idx\n\n# Check no duplicates across train/valid set\ntrn_idx, val_idx = random_splitter(trn_df)\nprint(len(trn_idx), len(val_idx))\nset(trn_df.iloc[trn_idx][\"text\"]).intersection(set((trn_df.iloc[val_idx][\"text\"])))\n\n6091 1522\n\n\nset()\n\n\nテストデータをざっくりと見ると、トレーニングデータと似通ったtweetデータが含まれていることが分かります。\n\ntst_df.head()\n\n\n\n\n\n\n\n\nid\nkeyword\nlocation\ntext\n\n\n\n\n0\n0\nNaN\nNaN\nJust happened a terrible car crash\n\n\n1\n2\nNaN\nNaN\nHeard about #earthquake is different cities, stay safe everyone.\n\n\n2\n3\nNaN\nNaN\nthere is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all\n\n\n3\n9\nNaN\nNaN\nApocalypse lighting. #Spokane #wildfires\n\n\n4\n11\nNaN\nNaN\nTyphoon Soudelor kills 28 in China and Taiwan\n\n\n\n\n\n\n\n\ntst_df.describe(include=\"object\")\n\n\n\n\n\n\n\n\nkeyword\nlocation\ntext\n\n\n\n\ncount\n3237\n2158\n3263\n\n\nunique\n221\n1602\n3243\n\n\ntop\ndeluged\nNew York\n11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...\n\n\nfreq\n23\n38\n3\n\n\n\n\n\n\n\n次のcombine_cols関数は、keyword・location・textデータを繫げます。各行の合間に挟まれるxxfldはテキストを繋げる際に使用される、fastaiのデフォルトのトークン(参照リンク)です。\n\n# Ref: https://github.com/fastai/fastai/blob/master/fastai/text/core.py#L199\ndef combine_cols(df): return \"xxfld 1 \" + df[\"keyword\"].fillna(\"\") + \" xxfld 2 \" + df[\"location\"].fillna(\"\") + \" xxfld 3 \" + df[\"text\"]\ntrn_df[\"text\"] = combine_cols(trn_df)\ntst_df[\"text\"] = combine_cols(tst_df)\n\ntrn_df[\"text\"].head(), tst_df[\"text\"].head()\n\n(0                                                                    xxfld 1  xxfld 2  xxfld 3 Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n 1                                                                                                   xxfld 1  xxfld 2  xxfld 3 Forest fire near La Ronge Sask. Canada\n 2    xxfld 1  xxfld 2  xxfld 3 All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n 3                                                                        xxfld 1  xxfld 2  xxfld 3 13,000 people receive #wildfires evacuation orders in California \n 4                                                 xxfld 1  xxfld 2  xxfld 3 Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n Name: text, dtype: object,\n 0                                                                  xxfld 1  xxfld 2  xxfld 3 Just happened a terrible car crash\n 1                                    xxfld 1  xxfld 2  xxfld 3 Heard about #earthquake is different cities, stay safe everyone.\n 2    xxfld 1  xxfld 2  xxfld 3 there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all\n 3                                                            xxfld 1  xxfld 2  xxfld 3 Apocalypse lighting. #Spokane #wildfires\n 4                                                       xxfld 1  xxfld 2  xxfld 3 Typhoon Soudelor kills 28 in China and Taiwan\n Name: text, dtype: object)\n\n\n分類学習モデル用のデータを用意し表示します。\n\ndef get_dls(df, seq_len=72, vocab=None, backwards=False, splitter=random_splitter, bs=256):\n    return DataBlock(\n        blocks=(TextBlock.from_df(\"text\", seq_len=seq_len, vocab=vocab, backwards=backwards), CategoryBlock),\n        get_x=ColReader(\"text\"),\n        get_y=ColReader(\"target\"),\n        splitter=splitter\n    ).dataloaders(df, bs=bs)\n\ndls = get_dls(trn_df)\ndls.show_batch(max_n=5)\n\n\n\n\n\n\n\n\n\n\n\n\ntext\ncategory\n\n\n\n\n0\nxxbos xxfld 1 army xxfld 2 xxmaj pakistan xxfld 3 . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : xxup rt xxunk : # xxunk \\n\\n xxmaj indian xxmaj army xxunk _ http : / / t.co / xxunk g\n0\n\n\n1\nxxbos xxfld 1 curfew xxfld 2 xxmaj adelaide , xxmaj australia xxfld 3 xxup info xxup r. xxup curfew xxup in xxup oper xxup until 2030 xxup z. xxup taxiways xxup foxtrot 5 & & xxup foxtrot 6 xxup navbl . xxup wnd : xxunk / 5 . xxup exp xxup inst xxup apch . xxup rwy 05 . xxup xxunk . xxup tmp : 10 . xxup xxunk : xxunk .\n0\n\n\n2\nxxbos xxfld 1 curfew xxfld 2 xxmaj adelaide , xxmaj australia xxfld 3 xxup info xxup s. xxup wnd : xxunk / 6 . xxup xxunk : xxup xxunk xxup xxunk . xxup exp xxup inst xxup apch . xxup rwy 05 . xxup curfew xxup in xxup oper xxup until 2030 xxup z. xxup taxiways xxup foxtrot 5 & & xxup foxtrot 6 xxup navbl . xxup tmp : 10 .\n0\n\n\n3\nxxbos xxfld 1 death xxfld 2 xxup xxunk ? ? xxfld 3 i xxmaj hate xxmaj to xxmaj talking xxmaj xxunk xxmaj with xxmaj my xxmaj xxunk … i xxmaj mean i xxmaj love xxmaj her xxmaj as xxmaj to xxmaj death xxmaj but xxmaj she xxmaj talk xxmaj so xxmaj damn xxmaj much xxmaj xxunk xxrep 3 h xxrep 3 e xxunk xxrep 3 ! xxrep 6 ?\n0\n\n\n4\nxxbos xxfld 1 hostages xxfld 2 xxfld 3 xxmaj no # news of # hostages in # xxmaj libya \\n\\n http : / / t.co / xxunk \\n\\n▁ # xxmaj india # terrorism # xxmaj africa # xxup ap # xxup ts # xxup nri # xxmaj news # xxup trs # xxup tdp # xxup bjp http : / / t.co / xxunk\n1\n\n\n\n\n\n\n\n\nデータセットの用意ができたら、分類モデルの作成を行います。モデルにはAWD_LSTM を使用します。少ないトレーニングデータ(約7000サンプル数)のため、モデルは直ぐに過学習に達します。\nでは、過学習はどのように対処していくのか？ということを考えてみます。よくある間違いはモデルの複雑性を減らし、パラメーター数の少ないモデルに変えることです。これは最後に行うステップです。まずは、過学習にはより多くのデータを使用することを第一 に考えます。単純な例として、ここではテキストを逆方法に、最後の文字→最初の文字へと学習させてみましょう(厳密に言うとデータ拡張になりますが、あまり気にしないでください)。\n\ndef get_classifier(dls, backwards=False): return text_classifier_learner(dls, AWD_LSTM, backwards=backwards, drop_mult=0.5, metrics=[Perplexity, F1Score()]).to_fp16()\nlearn = get_classifier(dls)\nlearn.lr_find()\n\n\n\n\n\n\n    \n      \n      100.00% [105070592/105067061 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.001737800776027143)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(6, 5e-3, wd=0.03)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.658422\n0.599893\n1.821924\n0.639466\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.588272\n0.534196\n1.706076\n0.669864\n00:08\n\n\n1\n0.563553\n0.489243\n1.631081\n0.687669\n00:09\n\n\n2\n0.535022\n0.486653\n1.626862\n0.716150\n00:09\n\n\n3\n0.507074\n0.464368\n1.591009\n0.725888\n00:08\n\n\n4\n0.482312\n0.454961\n1.576113\n0.728656\n00:09\n\n\n5\n0.461974\n0.456902\n1.579175\n0.738664\n00:08\n\n\n\n\n\n\nlearn.show_results(max_n=4)\n\n\n\n\n\n\n\n\n\n\n\n\ntext\ncategory\ncategory_\n\n\n\n\n0\nxxbos xxfld 1 mayhem xxfld 2 ? ? xxmaj made in the xxmaj philippines ? ? xxfld 3 _ \\n▁ xxrep 5 ? xxup retweet \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup follow xxup all xxup who xxup rt \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup xxunk \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup gain xxup with \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup follow ? xxunk # xxup xxunk \\n▁ # xxup ty\n0\n0\n\n\n1\nxxbos xxfld 1 curfew xxfld 2 xxmaj adelaide , xxmaj australia xxfld 3 xxup info xxup u. xxup xxunk : xxup xxunk xxup xxunk . xxup exp xxup inst xxup apch . xxup rwy 05 . xxup curfew xxup in xxup oper xxup until 2030 xxup z. xxup taxiways xxup foxtrot 5 & & xxup foxtrot 6 xxup navbl . xxup tmp : 10 . xxup wnd : xxunk / 6 .\n0\n0\n\n\n2\nxxbos xxfld 1 weapon xxfld 2 xxmaj washington xxup dc xxfld 3 xxmaj rare xxunk into # terror and xxmaj how to fight it http : / / t.co / xxunk # xxmaj cameroon # xxup usa # xxmaj xxunk # xxup xxunk # xxup fr # xxmaj nigeria # xxup uk # xxmaj africa # xxup de # xxup ca # xxup au # xxup xxunk\n1\n1\n\n\n3\nxxbos xxfld 1 casualties xxfld 2 xxmaj the low - xxunk xxmaj xxunk xxmaj zone xxfld 3 xxup i 'm xxup laughing xxup in xxup the xxup face xxup of xxup casualties xxup and xxup xxunk xxup the xxup first xxup time xxup i 'm xxup thinking xxup past xxup tomorrow xxup but i xxup am xxup not xxup xxunk xxup away xxup my xxup shot\n1\n0\n\n\n\n\n\n逆さ文章を表示した後、モデルを学習します。先の(順方向)モデルと比較しても、今回の(逆方向)モデルも妥当なスコアを出すことが分かります。ここでの注意ポイントは、データと合わせてモデルにもbackwards=Trueを渡すことです。逆方向に合わせた学習済み重みが、backwardsを設定することで、転移学習に使用されます。詳細はこちらのコードの確認を。\n\nget_dls(trn_df, backwards=True).show_batch(max_n=2)\n\n\n\n\n\n\n\n\n\n\n\n\ntext\ncategory\n\n\n\n\n0\nty xxup # \\n▁ xxunk xxup # xxunk ? follow xxup ? 5 xxrep \\n▁ ? 7 xxrep \\n▁ with xxup gain xxup ? 5 xxrep \\n▁ ? 7 xxrep \\n▁ xxunk xxup ? 5 xxrep \\n▁ ? 7 xxrep \\n▁ rt xxup who xxup all xxup follow xxup ? 5 xxrep \\n▁ ? 7 xxrep \\n▁ retweet xxup ? 5 xxrep \\n▁ _ 3 xxfld ? ? philippines xxmaj the in made xxmaj ? ? 2 xxfld mayhem 1 xxfld xxbos\n0\n\n\n1\n. 6 / xxunk : wnd xxup . 10 : tmp xxup . navbl xxup 6 foxtrot xxup & & 5 foxtrot xxup taxiways xxup z. xxup 2030 until xxup oper xxup in xxup curfew xxup . 05 rwy xxup . apch xxup inst xxup exp xxup . xxunk xxup xxunk xxup : xxunk xxup u. xxup info xxup 3 xxfld australia xxmaj , adelaide xxmaj 2 xxfld curfew 1 xxfld xxbos\n0\n\n\n\n\n\n\nlearn = get_classifier(get_dls(trn_df, backwards=True), backwards=True)\nlearn.fine_tune(6, 5e-3, wd=0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      100.00% [105209856/105205312 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.612321\n0.539246\n1.714714\n0.700943\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.543969\n0.488203\n1.629385\n0.699911\n00:08\n\n\n1\n0.522194\n0.463604\n1.589794\n0.740679\n00:08\n\n\n2\n0.499041\n0.445374\n1.561074\n0.750000\n00:08\n\n\n3\n0.477004\n0.440480\n1.553453\n0.751048\n00:08\n\n\n4\n0.455625\n0.441258\n1.554661\n0.763072\n00:09\n\n\n5\n0.436592\n0.443257\n1.557772\n0.763309\n00:09\n\n\n\n\n\n\n\n\nでは、kaggleに提出用のファイルを作成します。4つのモデル(2順方向・2逆方向)を組み合わせて、最終スコアの精度を上げます。\n\npreds = []\nfor i in range(4):\n    backwards = (i%2==1)\n    learn = get_classifier(get_dls(trn_df, backwards=backwards), backwards=backwards)\n    learn.fine_tune(8, 5e-3, wd=0.03)\n    pred = learn.get_preds(dl=learn.dls.test_dl(tst_df))[0]\n    preds.append(pred)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.677151\n0.617163\n1.853663\n0.687425\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.590248\n0.495130\n1.640712\n0.711262\n00:08\n\n\n1\n0.571887\n0.506855\n1.660062\n0.724490\n00:09\n\n\n2\n0.544579\n0.436301\n1.546974\n0.751494\n00:09\n\n\n3\n0.515391\n0.433388\n1.542475\n0.780450\n00:09\n\n\n4\n0.491986\n0.433089\n1.542014\n0.789033\n00:09\n\n\n5\n0.470065\n0.429307\n1.536193\n0.789147\n00:08\n\n\n6\n0.448351\n0.434152\n1.543654\n0.787510\n00:09\n\n\n7\n0.431437\n0.424780\n1.529254\n0.790008\n00:09\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.617464\n0.540031\n1.716060\n0.726718\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.537951\n0.481259\n1.618110\n0.735294\n00:09\n\n\n1\n0.524030\n0.496447\n1.642873\n0.757093\n00:08\n\n\n2\n0.505570\n0.458025\n1.580948\n0.772795\n00:08\n\n\n3\n0.482626\n0.456221\n1.578099\n0.768526\n00:09\n\n\n4\n0.459708\n0.446411\n1.562694\n0.766458\n00:09\n\n\n5\n0.437200\n0.456399\n1.578380\n0.783704\n00:09\n\n\n6\n0.414401\n0.454099\n1.574754\n0.779789\n00:09\n\n\n7\n0.401246\n0.452466\n1.572185\n0.781155\n00:08\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.657558\n0.589393\n1.802894\n0.703857\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.603144\n0.505390\n1.657633\n0.718028\n00:09\n\n\n1\n0.579316\n0.457990\n1.580893\n0.722569\n00:09\n\n\n2\n0.551933\n0.453589\n1.573950\n0.752672\n00:09\n\n\n3\n0.523351\n0.459823\n1.583794\n0.761835\n00:09\n\n\n4\n0.494781\n0.451828\n1.571181\n0.774340\n00:09\n\n\n5\n0.470976\n0.442031\n1.555864\n0.778774\n00:09\n\n\n6\n0.449637\n0.433513\n1.542667\n0.777948\n00:09\n\n\n7\n0.433776\n0.442702\n1.556909\n0.777022\n00:09\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.614581\n0.544251\n1.723318\n0.724109\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.539059\n0.456626\n1.578739\n0.762353\n00:09\n\n\n1\n0.518621\n0.436470\n1.547236\n0.775324\n00:09\n\n\n2\n0.500680\n0.427625\n1.533611\n0.783975\n00:08\n\n\n3\n0.480591\n0.423821\n1.527788\n0.796325\n00:09\n\n\n4\n0.458144\n0.416781\n1.517070\n0.779984\n00:09\n\n\n5\n0.437416\n0.421846\n1.524774\n0.796636\n00:09\n\n\n6\n0.418690\n0.423488\n1.527280\n0.793529\n00:08\n\n\n7\n0.405416\n0.421054\n1.523567\n0.795966\n00:08\n\n\n\n\n\n\n\n\n\n\n\n\n\nsmp_df[\"target\"] = torch.max(sum(preds), dim=-1).indices\nsmp_df.to_csv(path/\"submission.csv\", index=False)\n!head {path}/submission.csv\n\nid,target\n0,1\n2,1\n3,1\n9,1\n11,1\n12,1\n21,0\n22,0\n27,0\n\n\n\nfrom kaggle import api\napi.competition_submit_cli(path/\"submission.csv\", \"finetuned model\", comp)\n\n100%|██████████| 22.2k/22.2k [00:00&lt;00:00, 71.2kB/s]\n\n\nSuccessfully submitted to Natural Language Processing with Disaster Tweets\n\n\n最後に先にインストールしたデータを削除します。\n\n!rm -rf {path}\n!rm nlp-getting-started.zip\n\n\n\n\n\n\n\nkaggle の結果\n\n\n目標値80% f1 scoreを達成することができました。次のブログでは、Jeremy Howardさんの論文から、ulmfitで使用された転移学習のやり方を見ていきます。\nもしも読者がこのノートを役に立ったと思ったら、リアクションボタンを押してもらえると幸いです。質問や間違いがあれば、以下コメント欄に書き込んでください。\n\n\n\n\nkaggle公式競技ページ\nfastai NLP チュートリアル\ntext_classifier_learner関数のドキュメント"
  },
  {
    "objectID": "posts/tweet_kaggle/index.html#必要なライブラリのインストール",
    "href": "posts/tweet_kaggle/index.html#必要なライブラリのインストール",
    "title": "tweetデータを用いた自然言語分類モデルをつくってみる①",
    "section": "",
    "text": "競技参加の同意・APIキーの取得を、テータセットのインストール前に行っていきましょう。\n\ntry: import fastkaggle\nexcept ModuleNotFoundError:\n    %pip install -Uq fastkaggle\n\nfrom fastkaggle import *\nfrom fastai.text.all import *\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n!mkdir /root/.config/kaggle\n!touch /root/.config/kaggle/kaggle.json"
  },
  {
    "objectID": "posts/tweet_kaggle/index.html#分類モデル用データセットを用意",
    "href": "posts/tweet_kaggle/index.html#分類モデル用データセットを用意",
    "title": "tweetデータを用いた自然言語分類モデルをつくってみる①",
    "section": "",
    "text": "tweetデータはcsvファイルで取得されます。各データセットのサンプル数は、トレーニングが7613、テストが3263です。一つの列に対して、1tweet・対応するラベル(1が災害、0が災害以外のtweet)が含まれています。\n\ncomp = \"nlp-getting-started\"\n\npath = setup_comp(comp)\npath.ls()\n\nWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.config/kaggle/kaggle.json'\n\n\n(#3) [Path('nlp-getting-started/sample_submission.csv'),Path('nlp-getting-started/test.csv'),Path('nlp-getting-started/train.csv')]\n\n\n\ntrn_df = pd.read_csv(path/\"train.csv\")\ntst_df = pd.read_csv(path/\"test.csv\")\nsmp_df = pd.read_csv(path/\"sample_submission.csv\")\n\ntrn_df.shape, tst_df.shape, smp_df.shape\n\n((7613, 5), (3263, 4), (3263, 2))\n\n\n\ntrn_df.head()\n\n\n\n\n\n\n\n\nid\nkeyword\nlocation\ntext\ntarget\n\n\n\n\n0\n1\nNaN\nNaN\nOur Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n1\n\n\n1\n4\nNaN\nNaN\nForest fire near La Ronge Sask. Canada\n1\n\n\n2\n5\nNaN\nNaN\nAll residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n1\n\n\n3\n6\nNaN\nNaN\n13,000 people receive #wildfires evacuation orders in California\n1\n\n\n4\n7\nNaN\nNaN\nJust got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school\n1\n\n\n\n\n\n\n\nトレーニングデータにはいくつかの重複データが含まれていますが、特にtextデータの重複には注意が必要です。学習・検証データを作成する際に、同一データが二つのデータセットにまたがって含まれないようにします。例えば、11-Year-Old Boy Charged...の文章が検証データに含まれている場合、学習データはそのtweetデータを含まないことになります。広く使用されているランダムな学習セットの用意は、このデータには不適切であることが分かります。\n\ntrn_df.describe(include=\"object\")\n\n\n\n\n\n\n\n\nkeyword\nlocation\ntext\n\n\n\n\ncount\n7552\n5080\n7613\n\n\nunique\n221\n3341\n7503\n\n\ntop\nfatalities\nUSA\n11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...\n\n\nfreq\n45\n104\n10\n\n\n\n\n\n\n\nここでは、以下の学習データセットに対してtargetの割合がどう変化するかを示します。面白い点は、keywordデータの欠如が災害tweetの割合を増やしている点です。一方locationデータの有無は、災害tweetの割合に影響を与えていません。これが何を示すのかは分かりませんが、keywordを含ませると何らかの情報(災害に関する)をモデルに渡すことが推測できます。\n\ndef plot_target(df, title=\"\"):\n    plt.figure(figsize=(8, 6))\n    plt.pie(df[\"target\"].value_counts(), labels=df[\"target\"].unique(), autopct='%1.1f%%')\n    plt.title(title)\n    plt.show()\n\nplot_target(trn_df, \"Distribution of Target Values\")\n\n\n\n\n\n\n\n\n\nplot_target(trn_df[pd.isna(trn_df.keyword)], \"Distribution of Target Values on nan keyword\")\n\n\n\n\n\n\n\n\n\nplot_target(trn_df[pd.isna(trn_df.location)], \"Distribution of Target Values on nan location\")\n\n\n\n\n\n\n\n\n以下の関数random_splitterは、学習・検証セット間の同一データの重複(data leakage)を防ぎます。\n\ndef random_splitter(df, val_pct=0.2):\n    df = df.copy()\n    df[\"uniq_text\"] = df[\"text\"].map(lambda x: hash(x))\n    uniq_text = df[\"uniq_text\"].unique()\n    val_text_ids = set(random.sample(list(uniq_text), int(len(uniq_text) * val_pct)))\n\n    trn_idx = df.index[~df[\"uniq_text\"].isin(val_text_ids)].tolist()\n    val_idx = df.index[df[\"uniq_text\"].isin(val_text_ids)].tolist()\n    return trn_idx, val_idx\n\n# Check no duplicates across train/valid set\ntrn_idx, val_idx = random_splitter(trn_df)\nprint(len(trn_idx), len(val_idx))\nset(trn_df.iloc[trn_idx][\"text\"]).intersection(set((trn_df.iloc[val_idx][\"text\"])))\n\n6091 1522\n\n\nset()\n\n\nテストデータをざっくりと見ると、トレーニングデータと似通ったtweetデータが含まれていることが分かります。\n\ntst_df.head()\n\n\n\n\n\n\n\n\nid\nkeyword\nlocation\ntext\n\n\n\n\n0\n0\nNaN\nNaN\nJust happened a terrible car crash\n\n\n1\n2\nNaN\nNaN\nHeard about #earthquake is different cities, stay safe everyone.\n\n\n2\n3\nNaN\nNaN\nthere is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all\n\n\n3\n9\nNaN\nNaN\nApocalypse lighting. #Spokane #wildfires\n\n\n4\n11\nNaN\nNaN\nTyphoon Soudelor kills 28 in China and Taiwan\n\n\n\n\n\n\n\n\ntst_df.describe(include=\"object\")\n\n\n\n\n\n\n\n\nkeyword\nlocation\ntext\n\n\n\n\ncount\n3237\n2158\n3263\n\n\nunique\n221\n1602\n3243\n\n\ntop\ndeluged\nNew York\n11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...\n\n\nfreq\n23\n38\n3\n\n\n\n\n\n\n\n次のcombine_cols関数は、keyword・location・textデータを繫げます。各行の合間に挟まれるxxfldはテキストを繋げる際に使用される、fastaiのデフォルトのトークン(参照リンク)です。\n\n# Ref: https://github.com/fastai/fastai/blob/master/fastai/text/core.py#L199\ndef combine_cols(df): return \"xxfld 1 \" + df[\"keyword\"].fillna(\"\") + \" xxfld 2 \" + df[\"location\"].fillna(\"\") + \" xxfld 3 \" + df[\"text\"]\ntrn_df[\"text\"] = combine_cols(trn_df)\ntst_df[\"text\"] = combine_cols(tst_df)\n\ntrn_df[\"text\"].head(), tst_df[\"text\"].head()\n\n(0                                                                    xxfld 1  xxfld 2  xxfld 3 Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n 1                                                                                                   xxfld 1  xxfld 2  xxfld 3 Forest fire near La Ronge Sask. Canada\n 2    xxfld 1  xxfld 2  xxfld 3 All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n 3                                                                        xxfld 1  xxfld 2  xxfld 3 13,000 people receive #wildfires evacuation orders in California \n 4                                                 xxfld 1  xxfld 2  xxfld 3 Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n Name: text, dtype: object,\n 0                                                                  xxfld 1  xxfld 2  xxfld 3 Just happened a terrible car crash\n 1                                    xxfld 1  xxfld 2  xxfld 3 Heard about #earthquake is different cities, stay safe everyone.\n 2    xxfld 1  xxfld 2  xxfld 3 there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all\n 3                                                            xxfld 1  xxfld 2  xxfld 3 Apocalypse lighting. #Spokane #wildfires\n 4                                                       xxfld 1  xxfld 2  xxfld 3 Typhoon Soudelor kills 28 in China and Taiwan\n Name: text, dtype: object)\n\n\n分類学習モデル用のデータを用意し表示します。\n\ndef get_dls(df, seq_len=72, vocab=None, backwards=False, splitter=random_splitter, bs=256):\n    return DataBlock(\n        blocks=(TextBlock.from_df(\"text\", seq_len=seq_len, vocab=vocab, backwards=backwards), CategoryBlock),\n        get_x=ColReader(\"text\"),\n        get_y=ColReader(\"target\"),\n        splitter=splitter\n    ).dataloaders(df, bs=bs)\n\ndls = get_dls(trn_df)\ndls.show_batch(max_n=5)\n\n\n\n\n\n\n\n\n\n\n\n\ntext\ncategory\n\n\n\n\n0\nxxbos xxfld 1 army xxfld 2 xxmaj pakistan xxfld 3 . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : xxup rt xxunk : # xxunk \\n\\n xxmaj indian xxmaj army xxunk _ http : / / t.co / xxunk g\n0\n\n\n1\nxxbos xxfld 1 curfew xxfld 2 xxmaj adelaide , xxmaj australia xxfld 3 xxup info xxup r. xxup curfew xxup in xxup oper xxup until 2030 xxup z. xxup taxiways xxup foxtrot 5 & & xxup foxtrot 6 xxup navbl . xxup wnd : xxunk / 5 . xxup exp xxup inst xxup apch . xxup rwy 05 . xxup xxunk . xxup tmp : 10 . xxup xxunk : xxunk .\n0\n\n\n2\nxxbos xxfld 1 curfew xxfld 2 xxmaj adelaide , xxmaj australia xxfld 3 xxup info xxup s. xxup wnd : xxunk / 6 . xxup xxunk : xxup xxunk xxup xxunk . xxup exp xxup inst xxup apch . xxup rwy 05 . xxup curfew xxup in xxup oper xxup until 2030 xxup z. xxup taxiways xxup foxtrot 5 & & xxup foxtrot 6 xxup navbl . xxup tmp : 10 .\n0\n\n\n3\nxxbos xxfld 1 death xxfld 2 xxup xxunk ? ? xxfld 3 i xxmaj hate xxmaj to xxmaj talking xxmaj xxunk xxmaj with xxmaj my xxmaj xxunk … i xxmaj mean i xxmaj love xxmaj her xxmaj as xxmaj to xxmaj death xxmaj but xxmaj she xxmaj talk xxmaj so xxmaj damn xxmaj much xxmaj xxunk xxrep 3 h xxrep 3 e xxunk xxrep 3 ! xxrep 6 ?\n0\n\n\n4\nxxbos xxfld 1 hostages xxfld 2 xxfld 3 xxmaj no # news of # hostages in # xxmaj libya \\n\\n http : / / t.co / xxunk \\n\\n▁ # xxmaj india # terrorism # xxmaj africa # xxup ap # xxup ts # xxup nri # xxmaj news # xxup trs # xxup tdp # xxup bjp http : / / t.co / xxunk\n1"
  },
  {
    "objectID": "posts/tweet_kaggle/index.html#分類モデルの作成",
    "href": "posts/tweet_kaggle/index.html#分類モデルの作成",
    "title": "tweetデータを用いた自然言語分類モデルをつくってみる①",
    "section": "",
    "text": "データセットの用意ができたら、分類モデルの作成を行います。モデルにはAWD_LSTM を使用します。少ないトレーニングデータ(約7000サンプル数)のため、モデルは直ぐに過学習に達します。\nでは、過学習はどのように対処していくのか？ということを考えてみます。よくある間違いはモデルの複雑性を減らし、パラメーター数の少ないモデルに変えることです。これは最後に行うステップです。まずは、過学習にはより多くのデータを使用することを第一 に考えます。単純な例として、ここではテキストを逆方法に、最後の文字→最初の文字へと学習させてみましょう(厳密に言うとデータ拡張になりますが、あまり気にしないでください)。\n\ndef get_classifier(dls, backwards=False): return text_classifier_learner(dls, AWD_LSTM, backwards=backwards, drop_mult=0.5, metrics=[Perplexity, F1Score()]).to_fp16()\nlearn = get_classifier(dls)\nlearn.lr_find()\n\n\n\n\n\n\n    \n      \n      100.00% [105070592/105067061 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.001737800776027143)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(6, 5e-3, wd=0.03)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.658422\n0.599893\n1.821924\n0.639466\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.588272\n0.534196\n1.706076\n0.669864\n00:08\n\n\n1\n0.563553\n0.489243\n1.631081\n0.687669\n00:09\n\n\n2\n0.535022\n0.486653\n1.626862\n0.716150\n00:09\n\n\n3\n0.507074\n0.464368\n1.591009\n0.725888\n00:08\n\n\n4\n0.482312\n0.454961\n1.576113\n0.728656\n00:09\n\n\n5\n0.461974\n0.456902\n1.579175\n0.738664\n00:08\n\n\n\n\n\n\nlearn.show_results(max_n=4)\n\n\n\n\n\n\n\n\n\n\n\n\ntext\ncategory\ncategory_\n\n\n\n\n0\nxxbos xxfld 1 mayhem xxfld 2 ? ? xxmaj made in the xxmaj philippines ? ? xxfld 3 _ \\n▁ xxrep 5 ? xxup retweet \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup follow xxup all xxup who xxup rt \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup xxunk \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup gain xxup with \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup follow ? xxunk # xxup xxunk \\n▁ # xxup ty\n0\n0\n\n\n1\nxxbos xxfld 1 curfew xxfld 2 xxmaj adelaide , xxmaj australia xxfld 3 xxup info xxup u. xxup xxunk : xxup xxunk xxup xxunk . xxup exp xxup inst xxup apch . xxup rwy 05 . xxup curfew xxup in xxup oper xxup until 2030 xxup z. xxup taxiways xxup foxtrot 5 & & xxup foxtrot 6 xxup navbl . xxup tmp : 10 . xxup wnd : xxunk / 6 .\n0\n0\n\n\n2\nxxbos xxfld 1 weapon xxfld 2 xxmaj washington xxup dc xxfld 3 xxmaj rare xxunk into # terror and xxmaj how to fight it http : / / t.co / xxunk # xxmaj cameroon # xxup usa # xxmaj xxunk # xxup xxunk # xxup fr # xxmaj nigeria # xxup uk # xxmaj africa # xxup de # xxup ca # xxup au # xxup xxunk\n1\n1\n\n\n3\nxxbos xxfld 1 casualties xxfld 2 xxmaj the low - xxunk xxmaj xxunk xxmaj zone xxfld 3 xxup i 'm xxup laughing xxup in xxup the xxup face xxup of xxup casualties xxup and xxup xxunk xxup the xxup first xxup time xxup i 'm xxup thinking xxup past xxup tomorrow xxup but i xxup am xxup not xxup xxunk xxup away xxup my xxup shot\n1\n0\n\n\n\n\n\n逆さ文章を表示した後、モデルを学習します。先の(順方向)モデルと比較しても、今回の(逆方向)モデルも妥当なスコアを出すことが分かります。ここでの注意ポイントは、データと合わせてモデルにもbackwards=Trueを渡すことです。逆方向に合わせた学習済み重みが、backwardsを設定することで、転移学習に使用されます。詳細はこちらのコードの確認を。\n\nget_dls(trn_df, backwards=True).show_batch(max_n=2)\n\n\n\n\n\n\n\n\n\n\n\n\ntext\ncategory\n\n\n\n\n0\nty xxup # \\n▁ xxunk xxup # xxunk ? follow xxup ? 5 xxrep \\n▁ ? 7 xxrep \\n▁ with xxup gain xxup ? 5 xxrep \\n▁ ? 7 xxrep \\n▁ xxunk xxup ? 5 xxrep \\n▁ ? 7 xxrep \\n▁ rt xxup who xxup all xxup follow xxup ? 5 xxrep \\n▁ ? 7 xxrep \\n▁ retweet xxup ? 5 xxrep \\n▁ _ 3 xxfld ? ? philippines xxmaj the in made xxmaj ? ? 2 xxfld mayhem 1 xxfld xxbos\n0\n\n\n1\n. 6 / xxunk : wnd xxup . 10 : tmp xxup . navbl xxup 6 foxtrot xxup & & 5 foxtrot xxup taxiways xxup z. xxup 2030 until xxup oper xxup in xxup curfew xxup . 05 rwy xxup . apch xxup inst xxup exp xxup . xxunk xxup xxunk xxup : xxunk xxup u. xxup info xxup 3 xxfld australia xxmaj , adelaide xxmaj 2 xxfld curfew 1 xxfld xxbos\n0\n\n\n\n\n\n\nlearn = get_classifier(get_dls(trn_df, backwards=True), backwards=True)\nlearn.fine_tune(6, 5e-3, wd=0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      100.00% [105209856/105205312 00:01&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.612321\n0.539246\n1.714714\n0.700943\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.543969\n0.488203\n1.629385\n0.699911\n00:08\n\n\n1\n0.522194\n0.463604\n1.589794\n0.740679\n00:08\n\n\n2\n0.499041\n0.445374\n1.561074\n0.750000\n00:08\n\n\n3\n0.477004\n0.440480\n1.553453\n0.751048\n00:08\n\n\n4\n0.455625\n0.441258\n1.554661\n0.763072\n00:09\n\n\n5\n0.436592\n0.443257\n1.557772\n0.763309\n00:09"
  },
  {
    "objectID": "posts/tweet_kaggle/index.html#kaggleに提出",
    "href": "posts/tweet_kaggle/index.html#kaggleに提出",
    "title": "tweetデータを用いた自然言語分類モデルをつくってみる①",
    "section": "",
    "text": "では、kaggleに提出用のファイルを作成します。4つのモデル(2順方向・2逆方向)を組み合わせて、最終スコアの精度を上げます。\n\npreds = []\nfor i in range(4):\n    backwards = (i%2==1)\n    learn = get_classifier(get_dls(trn_df, backwards=backwards), backwards=backwards)\n    learn.fine_tune(8, 5e-3, wd=0.03)\n    pred = learn.get_preds(dl=learn.dls.test_dl(tst_df))[0]\n    preds.append(pred)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.677151\n0.617163\n1.853663\n0.687425\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.590248\n0.495130\n1.640712\n0.711262\n00:08\n\n\n1\n0.571887\n0.506855\n1.660062\n0.724490\n00:09\n\n\n2\n0.544579\n0.436301\n1.546974\n0.751494\n00:09\n\n\n3\n0.515391\n0.433388\n1.542475\n0.780450\n00:09\n\n\n4\n0.491986\n0.433089\n1.542014\n0.789033\n00:09\n\n\n5\n0.470065\n0.429307\n1.536193\n0.789147\n00:08\n\n\n6\n0.448351\n0.434152\n1.543654\n0.787510\n00:09\n\n\n7\n0.431437\n0.424780\n1.529254\n0.790008\n00:09\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.617464\n0.540031\n1.716060\n0.726718\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.537951\n0.481259\n1.618110\n0.735294\n00:09\n\n\n1\n0.524030\n0.496447\n1.642873\n0.757093\n00:08\n\n\n2\n0.505570\n0.458025\n1.580948\n0.772795\n00:08\n\n\n3\n0.482626\n0.456221\n1.578099\n0.768526\n00:09\n\n\n4\n0.459708\n0.446411\n1.562694\n0.766458\n00:09\n\n\n5\n0.437200\n0.456399\n1.578380\n0.783704\n00:09\n\n\n6\n0.414401\n0.454099\n1.574754\n0.779789\n00:09\n\n\n7\n0.401246\n0.452466\n1.572185\n0.781155\n00:08\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.657558\n0.589393\n1.802894\n0.703857\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.603144\n0.505390\n1.657633\n0.718028\n00:09\n\n\n1\n0.579316\n0.457990\n1.580893\n0.722569\n00:09\n\n\n2\n0.551933\n0.453589\n1.573950\n0.752672\n00:09\n\n\n3\n0.523351\n0.459823\n1.583794\n0.761835\n00:09\n\n\n4\n0.494781\n0.451828\n1.571181\n0.774340\n00:09\n\n\n5\n0.470976\n0.442031\n1.555864\n0.778774\n00:09\n\n\n6\n0.449637\n0.433513\n1.542667\n0.777948\n00:09\n\n\n7\n0.433776\n0.442702\n1.556909\n0.777022\n00:09\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.614581\n0.544251\n1.723318\n0.724109\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nperplexity\nf1_score\ntime\n\n\n\n\n0\n0.539059\n0.456626\n1.578739\n0.762353\n00:09\n\n\n1\n0.518621\n0.436470\n1.547236\n0.775324\n00:09\n\n\n2\n0.500680\n0.427625\n1.533611\n0.783975\n00:08\n\n\n3\n0.480591\n0.423821\n1.527788\n0.796325\n00:09\n\n\n4\n0.458144\n0.416781\n1.517070\n0.779984\n00:09\n\n\n5\n0.437416\n0.421846\n1.524774\n0.796636\n00:09\n\n\n6\n0.418690\n0.423488\n1.527280\n0.793529\n00:08\n\n\n7\n0.405416\n0.421054\n1.523567\n0.795966\n00:08\n\n\n\n\n\n\n\n\n\n\n\n\n\nsmp_df[\"target\"] = torch.max(sum(preds), dim=-1).indices\nsmp_df.to_csv(path/\"submission.csv\", index=False)\n!head {path}/submission.csv\n\nid,target\n0,1\n2,1\n3,1\n9,1\n11,1\n12,1\n21,0\n22,0\n27,0\n\n\n\nfrom kaggle import api\napi.competition_submit_cli(path/\"submission.csv\", \"finetuned model\", comp)\n\n100%|██████████| 22.2k/22.2k [00:00&lt;00:00, 71.2kB/s]\n\n\nSuccessfully submitted to Natural Language Processing with Disaster Tweets\n\n\n最後に先にインストールしたデータを削除します。\n\n!rm -rf {path}\n!rm nlp-getting-started.zip"
  },
  {
    "objectID": "posts/tweet_kaggle/index.html#まとめ",
    "href": "posts/tweet_kaggle/index.html#まとめ",
    "title": "tweetデータを用いた自然言語分類モデルをつくってみる①",
    "section": "",
    "text": "kaggle の結果\n\n\n目標値80% f1 scoreを達成することができました。次のブログでは、Jeremy Howardさんの論文から、ulmfitで使用された転移学習のやり方を見ていきます。\nもしも読者がこのノートを役に立ったと思ったら、リアクションボタンを押してもらえると幸いです。質問や間違いがあれば、以下コメント欄に書き込んでください。"
  },
  {
    "objectID": "posts/tweet_kaggle/index.html#参照リンク",
    "href": "posts/tweet_kaggle/index.html#参照リンク",
    "title": "tweetデータを用いた自然言語分類モデルをつくってみる①",
    "section": "",
    "text": "kaggle公式競技ページ\nfastai NLP チュートリアル\ntext_classifier_learner関数のドキュメント"
  }
]